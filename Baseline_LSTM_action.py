import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence
import pandas as pd
import numpy as np
import glob
import os
from tqdm import tqdm
from model import * 

# --- 1. ì„¤ì • (Hyperparameters) ---
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

BATCH_SIZE = 256        # RTX 3060 í™œìš©ì„ ìœ„í•´ ë°°ì¹˜ í¬ê¸° ì¦ê°€
LR = 0.001
EPOCHS = 50             # ì¶©ë¶„í•œ í•™ìŠµì„ ìœ„í•´ ì„¤ì •
MAX_X = 105.0
MAX_Y = 68.0
MAX_TIME = 5700.0

ACTION_TO_IDX = {
    'Aerial Clearance': 0,
    'Block': 1,
    'Carry': 2,
    'Catch': 3,
    'Clearance': 4,
    'Cross': 5,
    'Deflection': 6,
    'Duel': 7,
    'Error': 8,
    'Foul': 9,
    'Foul_Throw': 10,
    'Goal': 11,
    'Goal Kick': 12,
    'Handball_Foul': 13,
    'Hit': 14,
    'Interception': 15,
    'Intervention': 16,
    'Offside': 17,
    'Out': 18,
    'Own Goal': 19,
    'Parry': 20,
    'Pass': 21,
    'Pass_Corner': 22,
    'Pass_Freekick': 23,
    'Penalty Kick': 24,
    'Recovery': 25,
    'Shot': 26,
    'Shot_Corner': 27,
    'Shot_Freekick': 28,
    'Tackle': 29,
    'Take-On': 30,
    'Throw-In': 31,
    'Other': 32  # ë§¤í•‘ë˜ì§€ ì•Šì€ ê°’ì´ë‚˜ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤
}


class SoccerActionAwareBaselineDataset(Dataset):
    def __init__(self, data_dir, action_map, max_len_embed=30):
        self.file_paths = glob.glob(os.path.join(data_dir, '*.csv'))
        self.action_map = action_map
        self.MAX_X = 105.0
        self.MAX_Y = 68.0
        self.MAX_TIME = 5700.0
        self.max_len_embed = max_len_embed

    def __len__(self):
        return len(self.file_paths)

    def __getitem__(self, idx):
        try:
            df = pd.read_csv(self.file_paths[idx])
            if len(df) < 2: return None
            
            # --- 1. Context ì¶”ì¶œ ---
            # Start Action
            first_action = df.iloc[0]['type_name']
            start_action_idx = self.action_map.get(first_action, self.action_map['Other'])
            
            # Length (Embeddingìš©, ìµœëŒ€ê°’ í´ë¦¬í•‘)
            # Baselineì€ ì—í”¼ì†Œë“œ ì „ì²´ ê¸¸ì´ë¥¼ ì”ë‹ˆë‹¤.
            ep_len = len(df) - 1 # ë§ˆì§€ë§‰ íƒ€ê²Ÿ ì œì™¸ ê¸¸ì´
            ep_len_idx = min(ep_len, self.max_len_embed - 1)
            
            # --- 2. Feature ì •ê·œí™” ---
            sx = df['start_x'].values / self.MAX_X
            sy = df['start_y'].values / self.MAX_Y
            ex = df['end_x'].values / self.MAX_X
            ey = df['end_y'].values / self.MAX_Y
            t  = df['time_seconds'].values / self.MAX_TIME
            
            features = np.stack([sx, sy, ex, ey, t], axis=1)
            
            # Input / Target
            target = features[-1, 2:4]
            input_seq = features[:-1]
            
            return (torch.FloatTensor(input_seq), 
                    torch.FloatTensor(target), 
                    start_action_idx, 
                    ep_len_idx)

        except Exception as e:
            return None

def action_aware_baseline_collate_fn(batch):
    batch = [item for item in batch if item is not None]
    if not batch: return None, None, None, None, None
    
    inputs, targets, start_acts, len_idxs = zip(*batch)
    
    lengths = torch.LongTensor([len(x) for x in inputs])
    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=0)
    targets = torch.stack(targets)
    start_acts = torch.LongTensor(start_acts)
    len_idxs = torch.LongTensor(len_idxs)
    
    return padded_inputs, targets, lengths, start_acts, len_idxs

def train_and_validate(model, train_loader, val_loader, optimizer, criterion, epochs):
    # Lossê°€ ì•„ë‹Œ 'ê±°ë¦¬ ì˜¤ì°¨'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ Best ëª¨ë¸ì„ íŒë‹¨í•©ë‹ˆë‹¤.
    best_dist_error = float('inf') 
    
    for epoch in range(epochs):
        print(f"\nEpoch {epoch+1}/{epochs}")
        
        # --- Train Loop ---
        model.train()
        train_loss = 0.0
        
        for batch in tqdm(train_loader, desc="Training"):
            inputs, targets, lengths, start_acts, len_idxs = batch
            
            if inputs is None: continue
            
            inputs = inputs.to(device)
            targets = targets.to(device)
            start_acts = start_acts.to(device) # ì¶”ê°€ë¨
            len_idxs = len_idxs.to(device)     # ì¶”ê°€ë¨
            
            # ëª¨ë¸ ì…ë ¥
            optimizer.zero_grad()
            outputs = model(inputs, lengths, start_acts, len_idxs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
        avg_train_loss = train_loss / len(train_loader)
        
        # --- Validation Loop ---
        model.eval()
        val_loss = 0.0
        total_dist_error = 0.0
        count = 0
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc="Validation"):
                inputs, targets, lengths = batch
                if inputs is None: continue
                
                inputs = inputs.to(device)
                targets = targets.to(device)
                start_acts = start_acts.to(device) # ì¶”ê°€ë¨
                len_idxs = len_idxs.to(device) 
                
                outputs = model(inputs, lengths, start_acts, len_idxs)
                
                # Loss ê³„ì‚° (MSE)
                loss = criterion(outputs, targets)
                val_loss += loss.item()
                
                # ê±°ë¦¬ ì˜¤ì°¨ ê³„ì‚° (Meter ë‹¨ìœ„ ë³µì›)
                pred_real_x = outputs[:, 0] * MAX_X
                pred_real_y = outputs[:, 1] * MAX_Y
                true_real_x = targets[:, 0] * MAX_X
                true_real_y = targets[:, 1] * MAX_Y
                
                # ìœ í´ë¦¬ë“œ ê±°ë¦¬
                dist = torch.sqrt((pred_real_x - true_real_x)**2 + (pred_real_y - true_real_y)**2)
                total_dist_error += dist.sum().item()
                count += inputs.size(0)
        
        avg_val_loss = val_loss / len(val_loader)
        avg_dist_error = total_dist_error / count if count > 0 else 0.0
        
        print(f"Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}")
        print(f"Val Avg Distance Error: {avg_dist_error:.4f} meters") # ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€ í‘œì‹œ
        
        # --- Best Model ì €ì¥ ë¡œì§ ìˆ˜ì • ---
        if avg_dist_error < best_dist_error:
            best_dist_error = avg_dist_error
            
            # ì €ì¥ í´ë” ìƒì„±
            os.makedirs('./weight', exist_ok=True)
            
            # íŒŒì¼ëª…ì— LRê³¼ ê±°ë¦¬ ì˜¤ì°¨(m)ë¥¼ í¬í•¨
            save_path = f'./weight/baseline_lr{LR}_dist{best_dist_error:.4f}m.pth'
            
            torch.save(model.state_dict(), save_path)
            print(f">> ğŸš€ Best model saved! (Error: {best_dist_error:.4f}m)")

# --- 5. ì‹¤í–‰ ---
if __name__ == "__main__":
    # ë°ì´í„° ê²½ë¡œ í™•ì¸ í•„ìš”
    train_dataset = SoccerActionAwareBaselineDataset('./data/train',ACTION_TO_IDX)
    val_dataset = SoccerActionAwareBaselineDataset('./data/val',ACTION_TO_IDX)
    
    # 3060 GPU ì‚¬ìš© ì‹œ num_workersë¥¼ ë†’ì—¬ ë°ì´í„° ë¡œë”© ë³‘ëª© í•´ê²° (4~8 ì¶”ì²œ)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, 
                              shuffle=True, collate_fn=action_aware_baseline_collate_fn, num_workers=4, pin_memory=True)
    
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, 
                            shuffle=False, collate_fn=action_aware_baseline_collate_fn, num_workers=4, pin_memory=True)
    
    # ëª¨ë¸ ì´ˆê¸°í™” (RTX 3060ìš© ì„¤ì •)
    model = ActionAwareBaselineLSTM(input_size=5, 
                 hidden_size=256, 
                 num_layers=3, 
                 output_size=2, 
                 dropout_rate=0.3,
                 # --- ì¶”ê°€ëœ íŒŒë¼ë¯¸í„° ---
                 num_actions=33,       # Action ì¢…ë¥˜ ê°œìˆ˜
                 max_len=30,           # ê¸¸ì´ ì„ë² ë”© ìµœëŒ€ê°’ (Baselineì€ Sequenceê°€ ê¸°ë¯€ë¡œ ì ì ˆíˆ ì¡°ì ˆ í•„ìš”, ì—¬ê¸°ì„  phaseì™€ ë§ì¶¤)
                 action_emb_dim=4,     # Action ì„ë² ë”© ì°¨ì›
                 len_emb_dim=4         # Length ì„ë² ë”© ì°¨ì›
                 ).to(device)
    
    optimizer = optim.Adam(model.parameters(), lr=LR)
    criterion = nn.MSELoss()
    
    train_and_validate(model, train_loader, val_loader, optimizer, criterion, EPOCHS)