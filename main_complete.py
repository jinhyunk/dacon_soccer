import os 
from tqdm import tqdm 
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# ì‘ì„±í•´ì£¼ì‹  utils.pyì™€ model.pyì—ì„œ í´ë˜ìŠ¤ë“¤ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
from utils import * 
from model import * 
# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
class Config:
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    BATCH_SIZE = 256        # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ 64ë¡œ ì¡°ì ˆ
    LR = 0.001
    EPOCHS = 50
    NUM_WORKERS = 4
    
    # ë°ì´í„° ì •ê·œí™” ìƒìˆ˜
    MAX_X = 105.0
    MAX_Y = 68.0
    MAX_TIME = 5700.0       # 95ë¶„
    EOS_VALUE = -1.0
    
    # ì„ë² ë”© ê´€ë ¨ ì„¤ì •
    NUM_ACTIONS = 33        # Action ì¢…ë¥˜ ê°œìˆ˜
    MAX_PHASE_LEN_EMBED = 30 # Phase ê¸¸ì´ ì„ë² ë”© ìµœëŒ€ê°’
    ACTION_EMB_DIM = 4      # ë§¤ ìŠ¤í… Action ì„ë² ë”© ì°¨ì›
    LEN_EMB_DIM = 4         # Length ì„ë² ë”© ì°¨ì›
    
    DOMAIN_INPUT_DIM = 2    # [NEW] ë„ë©”ì¸ í”¼ì²˜ ì°¨ì› (dx, dy, ddist, speed, norm_len)
    
    # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    INPUT_SIZE = 5          # [sx, sy, ex, ey, t]
    PHASE_HIDDEN = 32
    EPISODE_HIDDEN = 128
    DROPOUT = 0.4
    
    # ê²½ë¡œ
    TRAIN_DIR = './data/train'
    VAL_DIR = './data/val'
    WEIGHT_DIR = './weight'

print(f"âœ… ì‚¬ìš© ì¥ì¹˜: {Config.DEVICE}")
if torch.cuda.is_available():
    print(f"   - GPU: {torch.cuda.get_device_name(0)}")

# ==========================================
# 2. Training Engine
# ==========================================
def run_training():
    os.makedirs(Config.WEIGHT_DIR, exist_ok=True)
    
    print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    # utils.pyì— ì •ì˜ëœ Complete ë°ì´í„°ì…‹ ì‚¬ìš©
    train_dataset = SoccerCompleteDataset(Config.TRAIN_DIR)
    val_dataset = SoccerCompleteDataset(Config.VAL_DIR)
    
    # utils.pyì— ì •ì˜ëœ complete_collate_fn ì‚¬ìš©
    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, 
                              shuffle=True, collate_fn=complete_collate_fn, 
                              num_workers=Config.NUM_WORKERS, pin_memory=True)
    
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, 
                            shuffle=False, collate_fn=complete_collate_fn, 
                            num_workers=Config.NUM_WORKERS, pin_memory=True)
    
    print(f"   - Train Files: {len(train_dataset)}")
    print(f"   - Val Files: {len(val_dataset)}")

    # ëª¨ë¸ ì´ˆê¸°í™” (CompleteHierarchicalLSTM)
    model = CompleteHierarchicalLSTM(
        input_size=Config.INPUT_SIZE,
        phase_hidden=Config.PHASE_HIDDEN,
        episode_hidden=Config.EPISODE_HIDDEN,
        output_size=2,
        dropout=Config.DROPOUT,
        num_actions=Config.NUM_ACTIONS,
        action_emb_dim=Config.ACTION_EMB_DIM,
        max_phase_len=Config.MAX_PHASE_LEN_EMBED,
        len_emb_dim=Config.LEN_EMB_DIM,
        domain_input_dim=Config.DOMAIN_INPUT_DIM  # [NEW]
    ).to(Config.DEVICE)
    
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    criterion = nn.MSELoss()
    
    best_dist_error = float('inf')
    
    # --- Epoch Loop ---
    for epoch in range(Config.EPOCHS):
        print(f"\nTraining Epoch {epoch+1}/{Config.EPOCHS}")
        
        # 1. Train
        model.train()
        train_loss = 0.0
        
        for batch in tqdm(train_loader, desc="[Train]"):
            # Unpack 7 Items (ìˆœì„œ ì¤‘ìš”: collate_fn ë°˜í™˜ ìˆœì„œì™€ ì¼ì¹˜)
            padded_phases, padded_actions, phase_lengths, episode_lengths, targets, phase_len_ids, domain_features = batch
            
            if padded_phases is None: continue
            
            # Move to Device (ëª¨ë“  í…ì„œë¥¼ GPUë¡œ ì´ë™)
            padded_phases = padded_phases.to(Config.DEVICE)
            padded_actions = padded_actions.to(Config.DEVICE) # [NEW]
            phase_lengths = phase_lengths.to(Config.DEVICE)
            episode_lengths = episode_lengths.to(Config.DEVICE)
            targets = targets.to(Config.DEVICE)
            phase_len_ids = phase_len_ids.to(Config.DEVICE)
            domain_features = domain_features.to(Config.DEVICE) # [NEW]
            
            optimizer.zero_grad()
            
            # Forward (ì¸ì ìˆœì„œ í™•ì¸: model.forward ì •ì˜ì™€ ì¼ì¹˜)
            preds = model(padded_phases, padded_actions, phase_lengths, episode_lengths, phase_len_ids, domain_features)
            
            loss = criterion(preds, targets)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
        avg_train_loss = train_loss / len(train_loader)
        
        # 2. Validation
        model.eval()
        val_loss = 0.0
        total_dist_error = 0.0
        count = 0
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc="[Valid]"):
                padded_phases, padded_actions, phase_lengths, episode_lengths, targets, phase_len_ids, domain_features = batch
                
                if padded_phases is None: continue
                
                # Move to Device
                padded_phases = padded_phases.to(Config.DEVICE)
                padded_actions = padded_actions.to(Config.DEVICE)
                phase_lengths = phase_lengths.to(Config.DEVICE)
                episode_lengths = episode_lengths.to(Config.DEVICE)
                targets = targets.to(Config.DEVICE)
                phase_len_ids = phase_len_ids.to(Config.DEVICE)
                domain_features = domain_features.to(Config.DEVICE)
                
                # Forward
                preds = model(padded_phases, padded_actions, phase_lengths, episode_lengths, phase_len_ids, domain_features)
                
                loss = criterion(preds, targets)
                val_loss += loss.item()
                
                # ê±°ë¦¬ ì˜¤ì°¨ ê³„ì‚° (Meter)
                pred_real_x = preds[:, 0] * Config.MAX_X
                pred_real_y = preds[:, 1] * Config.MAX_Y
                true_real_x = targets[:, 0] * Config.MAX_X
                true_real_y = targets[:, 1] * Config.MAX_Y
                
                dist = torch.sqrt((pred_real_x - true_real_x)**2 + (pred_real_y - true_real_y)**2)
                total_dist_error += dist.sum().item()
                count += targets.size(0)
        
        avg_val_loss = val_loss / len(val_loader)
        avg_dist_error = total_dist_error / count if count > 0 else 0.0
        
        print(f"   Results: Train Loss {avg_train_loss:.5f} | Val Loss {avg_val_loss:.5f}")
        print(f"   ğŸ“ Avg Distance Error: {avg_dist_error:.4f} meters")
        
        # Best Model ì €ì¥
        # if avg_dist_error < best_dist_error:
        #     best_dist_error = avg_dist_error
        #     # íŒŒì¼ëª…ì— complete ëª…ì‹œ
        #     save_name = f"complete_hierarchical_lr{Config.LR}_dist{best_dist_error:.4f}m.pth"
        #     save_path = os.path.join(Config.WEIGHT_DIR, save_name)
        #     torch.save(model.state_dict(), save_path)
        #     print(f"   ğŸ’¾ Best Model Saved: {save_name}")

if __name__ == "__main__":
    run_training()