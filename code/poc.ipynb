{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b957f506",
   "metadata": {},
   "source": [
    "1. 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316c4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e90ce",
   "metadata": {},
   "source": [
    "2. 하이퍼파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19961946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = \"../data/phase_train.csv\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "LR = 1e-3\n",
    "HIDDEN_DIM = 64\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5ba55",
   "metadata": {},
   "source": [
    "3. 데이터 로드 및 전처리\n",
    "[ 학습 데이터 구분 ]\n",
    "- episode 별로 구분\n",
    "- phase 별로 구분\n",
    "- episode & phase 모두 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80c0e0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59346/59346 [00:05<00:00, 11457.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase 수 :  47405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/phase_train.csv\")\n",
    "df = df.sort_values([\"game_episode\", \"time_seconds\"]).reset_index(drop=True)\n",
    "\n",
    "def episode_wise_data(df):\n",
    "    episodes = []\n",
    "    targets = []\n",
    "\n",
    "    for _, g in tqdm(df.groupby(\"game_episode\")):\n",
    "        g = g.reset_index(drop=True)\n",
    "        if len(g) < 2:\n",
    "            continue\n",
    "\n",
    "        # 정규화된 좌표 준비\n",
    "        sx = g[\"start_x\"].values / 105.0\n",
    "        sy = g[\"start_y\"].values / 68.0\n",
    "        ex = g[\"end_x\"].values   / 105.0\n",
    "        ey = g[\"end_y\"].values   / 68.0\n",
    "\n",
    "        coords = []\n",
    "        for i in range(len(g)):\n",
    "            # 항상 start는 들어감\n",
    "            coords.append([sx[i], sy[i]])\n",
    "            # 마지막 행 이전까지만 end를 넣음 (마지막 end는 타깃이므로)\n",
    "            if i < len(g) - 1:\n",
    "                coords.append([ex[i], ey[i]])\n",
    "\n",
    "        seq = np.array(coords, dtype=\"float32\")        # [T, 2]\n",
    "        target = np.array([ex[-1], ey[-1]], dtype=\"float32\")  # 마지막 행 end_x, end_y\n",
    "\n",
    "        episodes.append(seq)\n",
    "        targets.append(target)\n",
    "    print(\"에피소드 수 : \", len(episodes))\n",
    "    return episodes, targets\n",
    "\n",
    "def phase_wise_data(df):\n",
    "    episodes = []\n",
    "    targets = []\n",
    "\n",
    "    for _, g in tqdm(df.groupby(\"phase\")):\n",
    "        g = g.reset_index(drop=True)\n",
    "        if len(g) < 2:\n",
    "            continue\n",
    "\n",
    "        # 정규화된 좌표 준비\n",
    "        sx = g[\"start_x\"].values / 105.0\n",
    "        sy = g[\"start_y\"].values / 68.0\n",
    "        ex = g[\"end_x\"].values   / 105.0\n",
    "        ey = g[\"end_y\"].values   / 68.0\n",
    "\n",
    "        coords = []\n",
    "        for i in range(len(g)):\n",
    "            # 항상 start는 들어감\n",
    "            coords.append([sx[i], sy[i]])\n",
    "            # 마지막 행 이전까지만 end를 넣음 (마지막 end는 타깃이므로)\n",
    "            if i < len(g) - 1:\n",
    "                coords.append([ex[i], ey[i]])\n",
    "\n",
    "        seq = np.array(coords, dtype=\"float32\")        # [T, 2]\n",
    "        target = np.array([ex[-1], ey[-1]], dtype=\"float32\")  # 마지막 행 end_x, end_y\n",
    "\n",
    "        episodes.append(seq)\n",
    "        targets.append(target)\n",
    "    print(\"phase 수 : \", len(episodes))\n",
    "    return episodes, targets\n",
    "\n",
    "def epi_pha_data(df):\n",
    "    episodes = []\n",
    "    targets = []\n",
    "\n",
    "    for _, g in tqdm(df.groupby([\"game_episode\", \"phase\"])):\n",
    "        g = g.reset_index(drop=True)\n",
    "        if len(g) < 2:\n",
    "            continue\n",
    "\n",
    "        # 정규화된 좌표 준비\n",
    "        sx = g[\"start_x\"].values / 105.0\n",
    "        sy = g[\"start_y\"].values / 68.0\n",
    "        ex = g[\"end_x\"].values   / 105.0\n",
    "        ey = g[\"end_y\"].values   / 68.0\n",
    "\n",
    "        coords = []\n",
    "        for i in range(len(g)):\n",
    "            # 항상 start는 들어감\n",
    "            coords.append([sx[i], sy[i]])\n",
    "            # 마지막 행 이전까지만 end를 넣음 (마지막 end는 타깃이므로)\n",
    "            if i < len(g) - 1:\n",
    "                coords.append([ex[i], ey[i]])\n",
    "\n",
    "        seq = np.array(coords, dtype=\"float32\")        # [T, 2]\n",
    "        target = np.array([ex[-1], ey[-1]], dtype=\"float32\")  # 마지막 행 end_x, end_y\n",
    "\n",
    "        episodes.append(seq)\n",
    "        targets.append(target)\n",
    "    print(\"에피소드 + phase 수 : \", len(episodes))\n",
    "    return episodes, targets\n",
    "\n",
    "# epi_wise_seq, epi_wise_targets = episode_wise_data(df)\n",
    "# pha_wise_seq, pha_wise_targets = phase_wise_data(df)\n",
    "episodes, targets = phase_wise_data(df)\n",
    "# episodes, targets = epi_pha_data(df)\n",
    "# both_seq, both_targets = epi_pha_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eac61c",
   "metadata": {},
   "source": [
    "4. Custom Dataset / DataLoader 정의 및 Validation 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a41fe2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train episodes: 37924 valid episodes: 9481\n"
     ]
    }
   ],
   "source": [
    "class EpisodeDataset(Dataset):\n",
    "    def __init__(self, episodes, targets):\n",
    "        self.episodes = episodes\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.episodes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = torch.tensor(self.episodes[idx])   # [T, 2]\n",
    "        tgt = torch.tensor(self.targets[idx])    # [2]\n",
    "        length = seq.size(0)\n",
    "        return seq, length, tgt\n",
    "\n",
    "def collate_fn(batch):\n",
    "    seqs, lengths, tgts = zip(*batch)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    padded = pad_sequence(seqs, batch_first=True)  # [B, T, 2]\n",
    "    tgts = torch.stack(tgts, dim=0)                # [B, 2]\n",
    "    return padded, lengths, tgts\n",
    "\n",
    "# 에피소드 단위 train / valid split\n",
    "idx_train, idx_valid = train_test_split(\n",
    "    np.arange(len(episodes)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "episodes_train = [episodes[i] for i in idx_train]\n",
    "targets_train  = [targets[i]  for i in idx_train]\n",
    "episodes_valid = [episodes[i] for i in idx_valid]\n",
    "targets_valid  = [targets[i]  for i in idx_valid]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    EpisodeDataset(episodes_train, targets_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    EpisodeDataset(episodes_valid, targets_valid),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "print(\"train episodes:\", len(episodes_train), \"valid episodes:\", len(episodes_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce6526",
   "metadata": {},
   "source": [
    "5. LSTM 베이스라인 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b858b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBaseline(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 2)  # (x_norm, y_norm)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: [B, T, 2], lengths: [B]\n",
    "        packed = pack_padded_sequence(\n",
    "            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        h_last = h_n[-1]      # [B, H] 마지막 layer의 hidden state\n",
    "        out = self.fc(h_last) # [B, 2]\n",
    "        return out\n",
    "\n",
    "model = LSTMBaseline(input_dim=2, hidden_dim=HIDDEN_DIM).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f81c7",
   "metadata": {},
   "source": [
    "6. 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "075741c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 593/593 [00:03<00:00, 197.29it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 533.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train_loss=0.0343 | valid_mean_dist=15.8117\n",
      " --> Best model updated! (dist=15.8117)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 593/593 [00:02<00:00, 251.59it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 540.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train_loss=0.0233 | valid_mean_dist=15.2145\n",
      " --> Best model updated! (dist=15.2145)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 593/593 [00:02<00:00, 255.09it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 560.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train_loss=0.0231 | valid_mean_dist=14.9441\n",
      " --> Best model updated! (dist=14.9441)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 593/593 [00:02<00:00, 249.91it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 561.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] train_loss=0.0229 | valid_mean_dist=14.8987\n",
      " --> Best model updated! (dist=14.8987)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 593/593 [00:02<00:00, 253.76it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 560.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] train_loss=0.0228 | valid_mean_dist=15.0660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_dist = float(\"inf\")\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X, lengths, y in tqdm(train_loader):\n",
    "        X, lengths, y = X.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X, lengths)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    # --- Valid: 평균 유클리드 거리 ---\n",
    "    model.eval()\n",
    "    dists = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, lengths, y in tqdm(valid_loader):\n",
    "            X, lengths, y = X.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n",
    "            pred = model(X, lengths)\n",
    "\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            true_np = y.cpu().numpy()\n",
    "\n",
    "            pred_x = pred_np[:, 0] * 105.0\n",
    "            pred_y = pred_np[:, 1] * 68.0\n",
    "            true_x = true_np[:, 0] * 105.0\n",
    "            true_y = true_np[:, 1] * 68.0\n",
    "\n",
    "            dist = np.sqrt((pred_x - true_x) ** 2 + (pred_y - true_y) ** 2)\n",
    "            dists.append(dist)\n",
    "\n",
    "    mean_dist = np.concatenate(dists).mean()  # 평균 유클리드 거리\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch}] \"\n",
    "        f\"train_loss={train_loss:.4f} | \"\n",
    "        f\"valid_mean_dist={mean_dist:.4f}\"\n",
    "    )\n",
    "\n",
    "    # ----- BEST MODEL 업데이트 -----\n",
    "    if mean_dist < best_dist:\n",
    "        best_dist = mean_dist\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\" --> Best model updated! (dist={best_dist:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d1e0bb",
   "metadata": {},
   "source": [
    "7. 평가 데이터셋 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04b3bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2414/2414 [00:04<00:00, 581.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Best Model Load\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "test_meta = pd.read_csv(\"../data/test.csv\")\n",
    "submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "\n",
    "submission = submission.merge(test_meta, on=\"game_episode\", how=\"left\")\n",
    "\n",
    "preds_x, preds_y = [], []\n",
    "\n",
    "for _, row in tqdm(submission.iterrows(), total=len(submission)):\n",
    "    g = pd.read_csv('../data' + row[\"path\"][1:]).reset_index(drop=True)\n",
    "\n",
    "    # 마지막 행 정보\n",
    "    last_row = g.iloc[-1]\n",
    "    last_phase = last_row[\"phase\"]\n",
    "    last_team = last_row[\"team_id\"]\n",
    "\n",
    "    # 마지막 phase 데이터\n",
    "    phase_df = g[g[\"phase\"] == last_phase]\n",
    "    input_df = phase_df\n",
    "    \n",
    "    # -----------\n",
    "    # case 1 : 마지막 phase 길이 >= 2\n",
    "    # if len(phase_df) >= 2:\n",
    "    #     input_df = phase_df\n",
    "    # -----------\n",
    "    # case 2 : 마지막 phase 길이 == 1\n",
    "    # else:\n",
    "    #     input_df = g\n",
    "        # prev_df = g[g[\"phase\"] < last_phase]\n",
    "        # prev_df = prev_df[prev_df[\"team_id\"] == last_team]\n",
    "\n",
    "        # 만약 추론할 phase와 동일한 팀의 phase가 없을 때는 그냥 episode 전체 데이터를 활용\n",
    "        # if len(prev_df) == 0:\n",
    "        #     input_df = g\n",
    "        # else:\n",
    "        #     prev_phase = prev_df[\"phase\"].max()\n",
    "        #     input_df = prev_df[prev_df[\"phase\"] == prev_phase]\n",
    "\n",
    "    # 정규화된 좌표 준비\n",
    "    sx = input_df[\"start_x\"].values / 105.0\n",
    "    sy = input_df[\"start_y\"].values / 68.0\n",
    "    ex = input_df[\"end_x\"].values / 105.0\n",
    "    ey = input_df[\"end_y\"].values / 68.0\n",
    "    \n",
    "    coords = []\n",
    "    for i in range(len(input_df)):\n",
    "        # start는 항상 존재하므로 그대로 사용\n",
    "        coords.append([sx[i], sy[i]])\n",
    "        # 마지막 행은 end_x가 NaN이므로 자동으로 제외됨\n",
    "        if i < len(input_df) - 1:\n",
    "            coords.append([ex[i], ey[i]])\n",
    "\n",
    "    seq = np.array(coords, dtype=\"float32\")  # [T, 2]\n",
    "\n",
    "    x = torch.tensor(seq).unsqueeze(0).to(DEVICE)      # [1, T, 2]\n",
    "    length = torch.tensor([seq.shape[0]]).to(DEVICE)   # [1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x, length).cpu().numpy()[0]       # [2], 정규화 좌표\n",
    "\n",
    "    preds_x.append(pred[0] * 105.0)\n",
    "    preds_y.append(pred[1] * 68.0)\n",
    "print(\"Inference Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a87dbd",
   "metadata": {},
   "source": [
    "8. 제출 Submission 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7204c4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: baseline_submit.csv\n"
     ]
    }
   ],
   "source": [
    "submission[\"end_x\"] = preds_x\n",
    "submission[\"end_y\"] = preds_y\n",
    "submission[[\"game_episode\", \"end_x\", \"end_y\"]].to_csv(\"../data/phase_submit2.csv\", index=False)\n",
    "print(\"Saved: baseline_submit.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
