{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ab626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    BATCH_SIZE = 256        \n",
    "    LR = 0.001\n",
    "    EPOCHS = 50\n",
    "    NUM_WORKERS = 0\n",
    "    \n",
    "    # Îç∞Ïù¥ÌÑ∞ ÏÉÅÏàò\n",
    "    MAX_X = 105.0\n",
    "    MAX_Y = 68.0\n",
    "    MAX_TIME = 5700.0\n",
    "    EOS_VALUE = 0.0 \n",
    "    \n",
    "    # Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞\n",
    "    NUM_ACTIONS = 33\n",
    "    MAX_PHASE_LEN_EMBED = 30\n",
    "    ACTION_EMB_DIM = 4\n",
    "    LEN_EMB_DIM = 4\n",
    "    \n",
    "    INPUT_SIZE = 5       # Phase LSTM Input\n",
    "    PHASE_HIDDEN = 64\n",
    "    EPISODE_HIDDEN = 256\n",
    "    DROPOUT = 0.3        \n",
    "    \n",
    "    TRAIN_DIR = './data_test/train'\n",
    "    VAL_DIR = './data_test/val'\n",
    "    WEIGHT_DIR = './weight'\n",
    "\n",
    "ACTION_TO_IDX = {\n",
    "    'Aerial Clearance': 0, 'Block': 1, 'Carry': 2, 'Catch': 3, 'Clearance': 4,\n",
    "    'Cross': 5, 'Deflection': 6, 'Duel': 7, 'Error': 8, 'Foul': 9,\n",
    "    'Foul_Throw': 10, 'Goal': 11, 'Goal Kick': 12, 'Handball_Foul': 13,\n",
    "    'Hit': 14, 'Interception': 15, 'Intervention': 16, 'Offside': 17,\n",
    "    'Out': 18, 'Own Goal': 19, 'Parry': 20, 'Pass': 21, 'Pass_Corner': 22,\n",
    "    'Pass_Freekick': 23, 'Penalty Kick': 24, 'Recovery': 25, 'Shot': 26,\n",
    "    'Shot_Corner': 27, 'Shot_Freekick': 28, 'Tackle': 29, 'Take-On': 30,\n",
    "    'Throw-In': 31, 'Other': 32\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationAwareDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.file_paths = glob.glob(os.path.join(data_dir, '*.csv'))\n",
    "        self.action_map = ACTION_TO_IDX\n",
    "    \n",
    "    def __len__(self): return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            df = pd.read_csv(self.file_paths[idx])\n",
    "            if len(df) < 2: return None\n",
    "            if 'phase' not in df.columns:\n",
    "                 df['phase'] = (df['team_id'] != df['team_id'].shift(1)).fillna(0).cumsum()\n",
    "\n",
    "            # Ï†ïÍ∑úÌôî\n",
    "            sx = df['start_x'].values / Config.MAX_X\n",
    "            sy = df['start_y'].values / Config.MAX_Y\n",
    "            ex = df['end_x'].values / Config.MAX_X\n",
    "            ey = df['end_y'].values / Config.MAX_Y\n",
    "            t  = df['time_seconds'].values / Config.MAX_TIME\n",
    "            \n",
    "            # ÏÉÅÎåÄ Ï¢åÌëú (Delta)\n",
    "            dx = ex - sx\n",
    "            dy = ey - sy\n",
    "            \n",
    "            # Phase Input Features\n",
    "            features = np.stack([sx, sy, dx, dy, t], axis=1)\n",
    "            target = np.array([ex[-1], ey[-1]]) \n",
    "            \n",
    "            input_features = features[:-1]\n",
    "            input_df = df.iloc[:-1].copy()\n",
    "            \n",
    "            phases_data, start_actions, phase_lens = [], [], []\n",
    "            phase_end_coords = [] # [NEW] Í∞Å PhaseÍ∞Ä ÎÅùÎÇú ÏúÑÏπò Ï†ÄÏû•\n",
    "            \n",
    "            for _, group in input_df.groupby('phase', sort=False):\n",
    "                p_feats = input_features[group.index]\n",
    "                eos = np.full((1, 5), Config.EOS_VALUE)\n",
    "                phases_data.append(torch.FloatTensor(np.vstack([p_feats, eos])))\n",
    "                \n",
    "                act_name = group.iloc[0]['type_name']\n",
    "                start_actions.append(self.action_map.get(act_name, 32))\n",
    "                phase_lens.append(min(len(group), Config.MAX_PHASE_LEN_EMBED - 1))\n",
    "                \n",
    "                # [NEW] Ïù¥ PhaseÏùò ÎßàÏßÄÎßâ Ï¢ÖÎ£å ÏúÑÏπò (Normalized)\n",
    "                last_x = group.iloc[-1]['end_x'] / Config.MAX_X\n",
    "                last_y = group.iloc[-1]['end_y'] / Config.MAX_Y\n",
    "                phase_end_coords.append([last_x, last_y])\n",
    "                \n",
    "            if not phases_data: return None\n",
    "            \n",
    "            return (phases_data, torch.FloatTensor(target), start_actions, phase_lens, torch.FloatTensor(phase_end_coords))\n",
    "        except: return None\n",
    "\n",
    "def location_aware_collate_fn(batch):\n",
    "    batch = [x for x in batch if x is not None]\n",
    "    if not batch: return (None,)*6\n",
    "    \n",
    "    b_phases, b_targets, b_acts, b_lens, b_coords = zip(*batch)\n",
    "    \n",
    "    all_phases, all_acts, all_lens_ids, ep_lens = [], [], [], []\n",
    "    for i in range(len(b_phases)):\n",
    "        all_phases.extend(b_phases[i])\n",
    "        all_acts.extend(b_acts[i])\n",
    "        all_lens_ids.extend(b_lens[i])\n",
    "        ep_lens.append(len(b_phases[i]))\n",
    "        \n",
    "    pad_phases = pad_sequence(all_phases, batch_first=True, padding_value=Config.EOS_VALUE)\n",
    "    phase_lengths = torch.LongTensor([len(p) for p in all_phases])\n",
    "    episode_lengths = torch.LongTensor(ep_lens)\n",
    "    targets = torch.stack(b_targets)\n",
    "    start_action_ids = torch.LongTensor(all_acts)\n",
    "    phase_len_ids = torch.LongTensor(all_lens_ids)\n",
    "    \n",
    "    # [NEW] Phase End Coords Padding (Batch, Max_Ep_Len, 2)\n",
    "    # Episode LSTM ÏûÖÎ†•Ïö©Ïù¥ÎØÄÎ°ú Episode Í∏∏Ïù¥ÎßåÌÅº Ìå®Îî©Ìï¥Ïïº Ìï®\n",
    "    coords_list = [torch.FloatTensor(c) for c in b_coords]\n",
    "    padded_coords = pad_sequence(coords_list, batch_first=True, padding_value=0.0)\n",
    "    \n",
    "    return pad_phases, phase_lengths, episode_lengths, targets, start_action_ids, phase_len_ids, padded_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1274c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationAwareHierarchicalLSTM(nn.Module):\n",
    "    def __init__(self, input_size=5, phase_hidden=64, episode_hidden=256, output_size=2, dropout=0.3,\n",
    "                 num_actions=33, max_phase_len=30, action_emb_dim=4, len_emb_dim=4):\n",
    "        super(LocationAwareHierarchicalLSTM, self).__init__()\n",
    "        \n",
    "        self.action_embedding = nn.Embedding(num_actions, action_emb_dim)\n",
    "        self.length_embedding = nn.Embedding(max_phase_len, len_emb_dim)\n",
    "        \n",
    "        # 1. Phase LSTM\n",
    "        self.phase_input_dim = input_size + action_emb_dim + len_emb_dim\n",
    "        self.phase_lstm = nn.LSTM(self.phase_input_dim, phase_hidden, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # 2. Episode LSTM (Input Size Ï¶ùÍ∞Ä!)\n",
    "        # ÏûÖÎ†•: [Phase_Summary(64) + Phase_End_Coord(2)]\n",
    "        self.episode_input_dim = phase_hidden + 2 \n",
    "        self.episode_lstm = nn.LSTM(self.episode_input_dim, episode_hidden, num_layers=2, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(episode_hidden, episode_hidden // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(episode_hidden // 2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, padded_phases, phase_lengths, episode_lengths, start_action_ids, phase_len_ids, padded_coords):\n",
    "        \"\"\"\n",
    "        padded_coords: (Batch, Max_Ep_Len, 2) - Í∞Å PhaseÍ∞Ä ÎÅùÎÇú Ïã§Ï†ú Ï¢åÌëú\n",
    "        \"\"\"\n",
    "        # --- A. Phase Level ---\n",
    "        action_emb = self.action_embedding(start_action_ids)\n",
    "        len_emb = self.length_embedding(phase_len_ids)\n",
    "        context_vector = torch.cat([action_emb, len_emb], dim=1)\n",
    "        \n",
    "        seq_len = padded_phases.size(1)\n",
    "        context_expanded = context_vector.unsqueeze(1).expand(-1, seq_len, -1)\n",
    "        phase_inputs = torch.cat([padded_phases, context_expanded], dim=2)\n",
    "        \n",
    "        packed_phases = pack_padded_sequence(phase_inputs, phase_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (phase_h_n, _) = self.phase_lstm(packed_phases)\n",
    "        phase_embeddings = phase_h_n[-1] # (Total_Phases, Phase_Hidden)\n",
    "        \n",
    "        # --- B. Episode Level Preparation ---\n",
    "        # 1. Phase EmbeddingÏùÑ Episode Îã®ÏúÑÎ°ú Îã§Ïãú Î¨∂Ïùå\n",
    "        phases_per_episode = torch.split(phase_embeddings, episode_lengths.tolist())\n",
    "        padded_phase_embs = pad_sequence(phases_per_episode, batch_first=True, padding_value=0)\n",
    "        \n",
    "        # 2. [ÌïµÏã¨] Phase Summary + Ïã§Ï†ú Ï¢åÌëú Í≤∞Ìï©\n",
    "        # padded_phase_embs: (Batch, Ep_Len, 64)\n",
    "        # padded_coords:     (Batch, Ep_Len, 2)\n",
    "        # -> episode_inputs: (Batch, Ep_Len, 66)\n",
    "        episode_inputs = torch.cat([padded_phase_embs, padded_coords], dim=2)\n",
    "        \n",
    "        # --- C. Episode LSTM ---\n",
    "        packed_episodes = pack_padded_sequence(episode_inputs, episode_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (episode_h_n, _) = self.episode_lstm(packed_episodes)\n",
    "        \n",
    "        # --- D. Residual Prediction ---\n",
    "        # Î™®Îç∏ÏùÄ \"ÎßàÏßÄÎßâ PhaseÍ∞Ä ÎÅùÎÇú ÏßÄÏ†ê\"ÏóêÏÑú \"ÏñºÎßàÎÇò Îçî Í∞ÄÎäîÏßÄ\"Î•º ÏòàÏ∏°\n",
    "        predicted_remaining_delta = self.regressor(episode_h_n[-1])\n",
    "        \n",
    "        # ÎßàÏßÄÎßâ PhaseÏùò Ïã§Ï†ú ÎÅù ÏúÑÏπò Ï∂îÏ∂ú (Batch, 2)\n",
    "        # padded_coordsÏóêÏÑú Í∞Å Î∞∞ÏπòÏùò ÎßàÏßÄÎßâ Ïú†Ìö®Ìïú Í∞í Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        batch_size = padded_coords.size(0)\n",
    "        last_coords = []\n",
    "        for i in range(batch_size):\n",
    "            length = episode_lengths[i]\n",
    "            last_coords.append(padded_coords[i, length-1, :])\n",
    "        last_known_pos = torch.stack(last_coords)\n",
    "        \n",
    "        final_prediction = last_known_pos + predicted_remaining_delta\n",
    "        \n",
    "        return final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealDistanceLoss(nn.Module):\n",
    "    def __init__(self, max_x=105.0, max_y=68.0):\n",
    "        super(RealDistanceLoss, self).__init__()\n",
    "        self.max_x = max_x\n",
    "        self.max_y = max_y\n",
    "        self.epsilon = 1e-6\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        diff_x = (pred[:, 0] - target[:, 0]) * self.max_x\n",
    "        diff_y = (pred[:, 1] - target[:, 1]) * self.max_y\n",
    "        distance = torch.sqrt(diff_x**2 + diff_y**2 + self.epsilon)\n",
    "        return distance.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    os.makedirs(Config.WEIGHT_DIR, exist_ok=True)\n",
    "    print(f\"‚úÖ Device: {Config.DEVICE}\")\n",
    "    print(\"üìÇ Îç∞Ïù¥ÌÑ∞ Î°úÎìú Ï§ë (Location Aware)...\")\n",
    "    \n",
    "    train_dataset = LocationAwareDataset(Config.TRAIN_DIR)\n",
    "    val_dataset = LocationAwareDataset(Config.VAL_DIR)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, \n",
    "                              shuffle=True, collate_fn=location_aware_collate_fn, \n",
    "                              num_workers=Config.NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, \n",
    "                            shuffle=False, collate_fn=location_aware_collate_fn, \n",
    "                            num_workers=Config.NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    model = LocationAwareHierarchicalLSTM(\n",
    "        input_size=Config.INPUT_SIZE,\n",
    "        phase_hidden=Config.PHASE_HIDDEN,\n",
    "        episode_hidden=Config.EPISODE_HIDDEN,\n",
    "        dropout=Config.DROPOUT\n",
    "    ).to(Config.DEVICE)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=Config.LR)\n",
    "    criterion = RealDistanceLoss(max_x=Config.MAX_X, max_y=Config.MAX_Y)\n",
    "    \n",
    "    best_dist_error = float('inf')\n",
    "    \n",
    "    for epoch in range(Config.EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config.EPOCHS}\"):\n",
    "            batch = [b.to(Config.DEVICE) for b in batch]\n",
    "            if batch[0] is None: continue\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # Input index: 6 is padded_coords\n",
    "            preds = model(batch[0], batch[1], batch[2], batch[4], batch[5], batch[6])\n",
    "            \n",
    "            loss = criterion(preds, batch[3])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        avg_train = train_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = [b.to(Config.DEVICE) for b in batch]\n",
    "                if batch[0] is None: continue\n",
    "                preds = model(batch[0], batch[1], batch[2], batch[4], batch[5], batch[6])\n",
    "                loss = criterion(preds, batch[3])\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"   Train: {avg_train:.4f}m | Val: {avg_val:.4f}m\")\n",
    "        \n",
    "        if avg_val < best_dist_error:\n",
    "            best_dist_error = avg_val\n",
    "            save_name = f\"location_aware_best.pth\"\n",
    "            torch.save(model.state_dict(), os.path.join(Config.WEIGHT_DIR, save_name))\n",
    "            print(f\"   üíæ Best Model Saved: {save_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
