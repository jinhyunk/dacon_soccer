import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence
import pandas as pd
import numpy as np
import glob
import os
from tqdm import tqdm
from trashcan.model import * 

# --- 1. ì„¤ì • (Hyperparameters) ---
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

BATCH_SIZE = 256        # RTX 3060 í™œìš©ì„ ìœ„í•´ ë°°ì¹˜ í¬ê¸° ì¦ê°€
LR = 0.001
EPOCHS = 50             # ì¶©ë¶„í•œ í•™ìŠµì„ ìœ„í•´ ì„¤ì •
MAX_X = 105.0
MAX_Y = 68.0
MAX_TIME = 5700.0

class SoccerBaselineDataset(Dataset):
    def __init__(self, data_dir):
        """
        Args:
            data_dir (str): ë°ì´í„° íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ (ì˜ˆ: './data/train')
        """
        # í´ë” ë‚´ì˜ ëª¨ë“  csv íŒŒì¼ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
        self.file_paths = glob.glob(os.path.join(data_dir, '*.csv'))
        
        # ì •ê·œí™” ìƒìˆ˜
        self.MAX_X = 105.0
        self.MAX_Y = 68.0
        self.MAX_TIME = 5700.0 # 95ë¶„

    def __len__(self):
        return len(self.file_paths)

    def __getitem__(self, idx):
        file_path = self.file_paths[idx]
        try:
            df = pd.read_csv(file_path)
            
            # ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´(ì´ë²¤íŠ¸ 1ê°œ ì´í•˜) ì˜ˆì¸¡ ë¶ˆê°€ -> None ë°˜í™˜ í›„ collate_fnì—ì„œ ì²˜ë¦¬
            if len(df) < 2:
                return None
            
            # --- 1. ì •ê·œí™” (Normalization) ---
            # ëª¨ë“  ì‹œì ì˜ ë°ì´í„°ë¥¼ ì •ê·œí™”
            sx = df['start_x'].values / self.MAX_X
            sy = df['start_y'].values / self.MAX_Y
            ex = df['end_x'].values / self.MAX_X
            ey = df['end_y'].values / self.MAX_Y
            t  = df['time_seconds'].values / self.MAX_TIME
            
            # (Seq_Len, 5) í˜•íƒœë¡œ í•©ì¹˜ê¸°
            features = np.stack([sx, sy, ex, ey, t], axis=1)
            
            # --- 2. Input / Target ë¶„ë¦¬ ---
            # Target: ì´ ì—í”¼ì†Œë“œì˜ 'ë§ˆì§€ë§‰' ì´ë²¤íŠ¸ì˜ ë„ì°© ìœ„ì¹˜ (end_x, end_y)
            target = features[-1, 2:4] # [end_x, end_y]
            
            # Input: ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ê¸° ì „ê¹Œì§€ì˜ ëª¨ë“  ìƒí™©
            # (ë§ˆì§€ë§‰ í–‰ ì œì™¸)
            input_seq = features[:-1]
            
            return torch.FloatTensor(input_seq), torch.FloatTensor(target)

        except Exception as e:
            print(f"Error loading {file_path}: {e}")
            return None

def baseline_collate_fn(batch):
    """
    ë°°ì¹˜ ë‚´ì˜ None ê°’(ì—ëŸ¬/ì§§ì€ ë°ì´í„°)ì„ ê±¸ëŸ¬ë‚´ê³  íŒ¨ë”© ì²˜ë¦¬
    """
    # None ì œê±°
    batch = [item for item in batch if item is not None]
    if len(batch) == 0:
        return None, None, None
    
    inputs, targets = zip(*batch)
    
    # ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ (pack_padded_sequenceìš©)
    lengths = torch.LongTensor([len(x) for x in inputs])
    
    # Padding (Batch, Max_Len, 5)
    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=0)
    
    # Targets (Batch, 2)
    targets = torch.stack(targets)
    
    return padded_inputs, targets, lengths

def train_and_validate(model, train_loader, val_loader, optimizer, criterion, epochs):
    # Lossê°€ ì•„ë‹Œ 'ê±°ë¦¬ ì˜¤ì°¨'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ Best ëª¨ë¸ì„ íŒë‹¨í•©ë‹ˆë‹¤.
    best_dist_error = float('inf') 
    
    for epoch in range(epochs):
        print(f"\nEpoch {epoch+1}/{epochs}")
        
        # --- Train Loop ---
        model.train()
        train_loss = 0.0
        
        for batch in tqdm(train_loader, desc="Training"):
            inputs, targets, lengths = batch
            if inputs is None: continue
            
            inputs, targets = inputs.to(device), targets.to(device)
            
            optimizer.zero_grad()
            outputs = model(inputs, lengths)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
        avg_train_loss = train_loss / len(train_loader)
        
        # --- Validation Loop ---
        model.eval()
        val_loss = 0.0
        total_dist_error = 0.0
        count = 0
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc="Validation"):
                inputs, targets, lengths = batch
                if inputs is None: continue
                
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs, lengths)
                
                # Loss ê³„ì‚° (MSE)
                loss = criterion(outputs, targets)
                val_loss += loss.item()
                
                # ê±°ë¦¬ ì˜¤ì°¨ ê³„ì‚° (Meter ë‹¨ìœ„ ë³µì›)
                pred_real_x = outputs[:, 0] * MAX_X
                pred_real_y = outputs[:, 1] * MAX_Y
                true_real_x = targets[:, 0] * MAX_X
                true_real_y = targets[:, 1] * MAX_Y
                
                # ìœ í´ë¦¬ë“œ ê±°ë¦¬
                dist = torch.sqrt((pred_real_x - true_real_x)**2 + (pred_real_y - true_real_y)**2)
                total_dist_error += dist.sum().item()
                count += inputs.size(0)
        
        avg_val_loss = val_loss / len(val_loader)
        avg_dist_error = total_dist_error / count if count > 0 else 0.0
        
        print(f"Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}")
        print(f"Val Avg Distance Error: {avg_dist_error:.4f} meters") # ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€ í‘œì‹œ
        
        # --- Best Model ì €ì¥ ë¡œì§ ìˆ˜ì • ---
        if avg_dist_error < best_dist_error:
            best_dist_error = avg_dist_error
            
            # ì €ì¥ í´ë” ìƒì„±
            os.makedirs('./weight', exist_ok=True)
            
            # íŒŒì¼ëª…ì— LRê³¼ ê±°ë¦¬ ì˜¤ì°¨(m)ë¥¼ í¬í•¨
            save_path = f'./weight/baseline_lr{LR}_dist{best_dist_error:.4f}m.pth'
            
            torch.save(model.state_dict(), save_path)
            print(f">> ğŸš€ Best model saved! (Error: {best_dist_error:.4f}m)")

# --- 5. ì‹¤í–‰ ---
if __name__ == "__main__":
    # ë°ì´í„° ê²½ë¡œ í™•ì¸ í•„ìš”
    train_dataset = SoccerBaselineDataset('./data/train')
    val_dataset = SoccerBaselineDataset('./data/val')
    
    # 3060 GPU ì‚¬ìš© ì‹œ num_workersë¥¼ ë†’ì—¬ ë°ì´í„° ë¡œë”© ë³‘ëª© í•´ê²° (4~8 ì¶”ì²œ)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, 
                              shuffle=True, collate_fn=baseline_collate_fn, num_workers=4, pin_memory=True)
    
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, 
                            shuffle=False, collate_fn=baseline_collate_fn, num_workers=4, pin_memory=True)
    
    # ëª¨ë¸ ì´ˆê¸°í™” (RTX 3060ìš© ì„¤ì •)
    model = BaselineLSTM(
        input_size=5, 
        hidden_size=256, 
        num_layers=3, 
        output_size=2, 
        dropout_rate=0.3
    ).to(device)
    
    optimizer = optim.Adam(model.parameters(), lr=LR)
    criterion = nn.MSELoss()
    
    train_and_validate(model, train_loader, val_loader, optimizer, criterion, EPOCHS)