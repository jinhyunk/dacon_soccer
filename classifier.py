import os
import glob
import numpy as np
import pandas as pd
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# ==========================================
# 0. Configuration
# ==========================================
class Config:
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    TRAIN_DIR = './open_track1' # train.csv ê²½ë¡œ
    MATCH_INFO_PATH = './open_track1/match_info.csv'
    WEIGHT_DIR = './weights_cls'
    
    BATCH_SIZE = 256
    LR = 0.001
    EPOCHS = 20 # ë¶„ë¥˜ ë¬¸ì œëŠ” ê¸ˆë°© ìˆ˜ë ´í•¨
    NUM_WORKERS = 4
    
    MAX_X = 105.0
    MAX_Y = 68.0
    MAX_TIME = 5700.0
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° (TeamGRUì™€ ë™ì¼í•œ Encoder êµ¬ì¡° ê¶Œì¥)
    NUM_ACTIONS = 33
    ACTION_EMB_DIM = 4
    NUM_TEAMS = 35
    TEAM_EMB_DIM = 4
    
    INPUT_SIZE = 5
    PHASE_HIDDEN = 64
    EPISODE_HIDDEN = 128
    NUM_LAYERS = 1
    
    # Output Class (Lose=0, Draw=1, Win=2)
    NUM_CLASSES = 3

# ì „ì—­ ë³€ìˆ˜ (Team ID ë§¤í•‘)
TEAM_TO_IDX = {}

ACTION_TO_IDX = {
    'Aerial Clearance': 0, 'Block': 1, 'Carry': 2, 'Catch': 3, 'Clearance': 4,
    'Cross': 5, 'Deflection': 6, 'Duel': 7, 'Error': 8, 'Foul': 9,
    'Foul_Throw': 10, 'Goal': 11, 'Goal Kick': 12, 'Handball_Foul': 13,
    'Hit': 14, 'Interception': 15, 'Intervention': 16, 'Offside': 17,
    'Out': 18, 'Own Goal': 19, 'Parry': 20, 'Pass': 21, 'Pass_Corner': 22,
    'Pass_Freekick': 23, 'Penalty Kick': 24, 'Recovery': 25, 'Shot': 26,
    'Shot_Corner': 27, 'Shot_Freekick': 28, 'Tackle': 29, 'Take-On': 30,
    'Throw-In': 31, 'Other': 32
}
DEFAULT_ACTION_IDX = 32

# ==========================================
# 1. Logic: Score Reconstruction from Kick-off
# ==========================================
def label_game_state(train_df, match_df):
    print("ğŸ”„ Reconstructing Scores based on Kick-off Logic...")
    
    # 1. Match Info ë³‘í•© (Home/Away ID í™•ì¸ìš©)
    train_df = train_df.merge(match_df[['game_id', 'home_team_id', 'away_team_id']], on='game_id', how='left')
    
    # 2. ì •ë ¬ (ë§¤ìš° ì¤‘ìš”)
    train_df = train_df.sort_values(['game_id', 'period_id', 'time_seconds'])
    
    # 3. Phase ë‹¨ìœ„ë¡œ ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ 'í‚¥ì˜¤í”„ ì—¬ë¶€' íŒë‹¨
    # (Phaseê°€ ì—†ìœ¼ë©´ ìƒì„±)
    if 'phase' not in train_df.columns:
        train_df['phase'] = (train_df['team_id'] != train_df['team_id'].shift(1)).fillna(0).cumsum()
    
    # ê° Phaseì˜ ì²« ë²ˆì§¸ í–‰ ì¶”ì¶œ
    phase_starts = train_df.groupby(['game_id', 'phase']).first().reset_index()
    
    # 4. í‚¥ì˜¤í”„ íƒì§€ ì¡°ê±´
    # ì¡°ê±´: Action == Pass AND ìœ„ì¹˜ê°€ ì¤‘ì•™(52.5, 34) ê·¼ì²˜
    # ê´€ìš© ë²”ìœ„(Tolerance): ì¤‘ì•™ì—ì„œ 2m ì´ë‚´ë¼ê³  ê°€ì •
    is_pass = phase_starts['type_name'] == 'Pass'
    center_x, center_y = 52.5, 34.0
    dist_from_center = np.sqrt((phase_starts['start_x'] - center_x)**2 + (phase_starts['start_y'] - center_y)**2)
    is_center = dist_from_center < 3.0 # 3ë¯¸í„° ì´ë‚´ ì˜¤ì°¨ í—ˆìš©
    
    phase_starts['is_kickoff'] = is_pass & is_center
    
    # 5. ìŠ¤ì½”ì–´ ì¶”ì  ë£¨í”„
    # ë²¡í„° ì—°ì‚°ì´ ì–´ë µê¸° ë•Œë¬¸ì— ê²Œì„ë³„ë¡œ ìˆœíšŒ (ë°ì´í„° í¬ê¸°ê°€ í¬ì§€ ì•Šì•„ ê°€ëŠ¥)
    
    phase_starts['home_score'] = 0
    phase_starts['away_score'] = 0
    
    # tqdmì„ ìœ„í•´ game_id ë³„ë¡œ ê·¸ë£¹í•‘
    game_groups = phase_starts.groupby('game_id')
    
    results = []
    
    for g_id, group in tqdm(game_groups, desc="Labeling Scores"):
        group = group.sort_values('time_seconds')
        
        curr_h = 0
        curr_a = 0
        
        # ì´ì „ period ì¶”ì  (í•˜í”„íƒ€ì„ êµ¬ë¶„ìš©)
        prev_period = -1
        
        for idx, row in group.iterrows():
            # ê¸°ê°„(ì „ë°˜/í›„ë°˜)ì´ ë°”ë€Œë©´ -> í•˜í”„íƒ€ì„ í‚¥ì˜¤í”„ (ê³¨ ì•„ë‹˜)
            if row['period_id'] != prev_period:
                prev_period = row['period_id']
                # ì ìˆ˜ ìœ ì§€, ë‹¤ìŒ ë£¨í”„ë¡œ
                pass
            
            # ê¸°ê°„ ì¤‘ì¸ë° í‚¥ì˜¤í”„ë‹¤? -> ì§ì „ì— ê³¨ì´ í„°ì§
            elif row['is_kickoff']:
                # ëˆ„ê°€ í‚¥ì˜¤í”„? -> ì‹¤ì í•œ íŒ€ì´ í‚¥ì˜¤í”„
                kicker_team = row['team_id']
                home_team = row['home_team_id']
                
                if kicker_team == home_team:
                    # í™ˆíŒ€ì´ í‚¥ì˜¤í”„ = ì–´ì›¨ì´íŒ€ì´ ë“ì 
                    curr_a += 1
                else:
                    # ì–´ì›¨ì´íŒ€ì´ í‚¥ì˜¤í”„ = í™ˆíŒ€ì´ ë“ì 
                    curr_h += 1
            
            # í˜„ì¬ ìŠ¤ì½”ì–´ ê¸°ë¡
            results.append({
                'phase': row['phase'],
                'current_home_score': curr_h,
                'current_away_score': curr_a
            })
            
    score_df = pd.DataFrame(results)
    
    # 6. ì›ë³¸ ë°ì´í„°ì— ìŠ¤ì½”ì–´ ë³‘í•©
    train_df = train_df.merge(score_df, on='phase', how='left')
    train_df['current_home_score'] = train_df['current_home_score'].fillna(method='ffill').fillna(0)
    train_df['current_away_score'] = train_df['current_away_score'].fillna(method='ffill').fillna(0)
    
    # 7. Win/Draw/Lose ë¼ë²¨ë§ (ë‚´ íŒ€ ê¸°ì¤€)
    # 0: Lose, 1: Draw, 2: Win
    
    is_home_team = (train_df['team_id'] == train_df['home_team_id'])
    
    my_score = np.where(is_home_team, train_df['current_home_score'], train_df['current_away_score'])
    opp_score = np.where(is_home_team, train_df['current_away_score'], train_df['current_home_score'])
    
    score_diff = my_score - opp_score
    
    conditions = [
        (score_diff < 0), # Lose
        (score_diff == 0), # Draw
        (score_diff > 0)  # Win
    ]
    choices = [0, 1, 2]
    
    train_df['game_state'] = np.select(conditions, choices, default=1)
    
    print("\nğŸ“Š Game State Label Distribution:")
    print(train_df.groupby('phase')['game_state'].first().value_counts().rename({0:'Lose', 1:'Draw', 2:'Win'}))
    
    return train_df

# ==========================================
# 2. Dataset
# ==========================================
class GameStateDataset(Dataset):
    def __init__(self, df):
        self.data = df
        self.action_map = ACTION_TO_IDX
        
        # Phase ë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ ì¸ë±ì‹± ì‚¬ìš© ê¶Œì¥í•˜ì§€ë§Œ ì—¬ê¸°ì„  ì§ê´€ì ìœ¼ë¡œ)
        self.phases = []
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬ ê·¸ë£¹í•‘ (ì†ë„ ìµœì í™”)
        cols = ['phase', 'start_x', 'start_y', 'end_x', 'end_y', 'time_seconds', 
                'type_name', 'team_id', 'game_state']
        
        grouped = self.data[cols].groupby('phase', sort=False)
        
        for _, group in tqdm(grouped, desc="Building Dataset"):
            if len(group) < 1: continue
            
            # Features
            sx = group['start_x'].values / Config.MAX_X
            sy = group['start_y'].values / Config.MAX_Y
            ex = group['end_x'].values / Config.MAX_X
            ey = group['end_y'].values / Config.MAX_Y
            t  = group['time_seconds'].values / Config.MAX_TIME
            
            dx = ex - sx
            dy = ey - sy
            
            feats = np.stack([sx, sy, dx, dy, t], axis=1)
            
            # Actions
            actions = [self.action_map.get(a, DEFAULT_ACTION_IDX) for a in group['type_name']]
            
            # Team ID
            raw_team = group.iloc[0]['team_id']
            team_idx = TEAM_TO_IDX.get(raw_team, 0)
            
            # Length
            raw_len = len(group)
            
            # Target (Label): Phaseì˜ ìƒíƒœëŠ” ë™ì¼í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
            label = group.iloc[0]['game_state']
            
            self.phases.append({
                'features': torch.FloatTensor(feats),
                'actions': torch.LongTensor(actions),
                'team_idx': torch.LongTensor([team_idx]),
                'raw_len': torch.FloatTensor([raw_len]),
                'label': torch.LongTensor([label])
            })
            
    def __len__(self): return len(self.phases)
    
    def __getitem__(self, idx):
        return self.phases[idx]

def collate_fn(batch):
    # Padding logic
    features = [b['features'] for b in batch]
    actions = [b['actions'] for b in batch]
    teams = [b['team_idx'] for b in batch]
    raw_lens = [b['raw_len'] for b in batch]
    labels = [b['label'] for b in batch]
    
    lengths = torch.LongTensor([len(f) for f in features])
    
    padded_feats = pad_sequence(features, batch_first=True, padding_value=0.0)
    padded_actions = pad_sequence(actions, batch_first=True, padding_value=DEFAULT_ACTION_IDX)
    
    return (padded_feats, lengths, padded_actions, 
            torch.cat(teams), torch.cat(raw_lens), torch.cat(labels))

# ==========================================
# 3. Model: GameStateRNN (Classifier)
# ==========================================
class GameStateRNN(nn.Module):
    def __init__(self):
        super(GameStateRNN, self).__init__()
        
        # 1. Embeddings
        self.action_embedding = nn.Embedding(Config.NUM_ACTIONS, Config.ACTION_EMB_DIM)
        self.team_embedding = nn.Embedding(Config.NUM_TEAMS, Config.TEAM_EMB_DIM)
        
        # Functional Length Feature
        self.len_encoder = nn.Sequential(nn.Linear(1, 4), nn.Tanh())
        
        # 2. Phase GRU (Encoder)
        # Input: Coords(5) + Action(4) + Team(4) + Len(4) = 17
        input_dim = Config.INPUT_SIZE + Config.ACTION_EMB_DIM + Config.TEAM_EMB_DIM + 4
        self.gru = nn.GRU(input_dim, Config.PHASE_HIDDEN, num_layers=1, batch_first=True)
        
        # 3. Classifier Head (Win/Draw/Lose)
        # GRUì˜ ë§ˆì§€ë§‰ Hidden Stateë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜
        self.classifier = nn.Sequential(
            nn.Linear(Config.PHASE_HIDDEN, 32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, Config.NUM_CLASSES) # Output: 3 (Logits)
        )

    def forward(self, padded_feats, lengths, padded_actions, team_ids, raw_lens):
        # Embeddings
        act_emb = self.action_embedding(padded_actions)
        team_emb = self.team_embedding(team_ids).unsqueeze(1).expand(-1, padded_feats.size(1), -1)
        
        # Length Feature
        len_feat = self.len_encoder(raw_lens.unsqueeze(1)).unsqueeze(1).expand(-1, padded_feats.size(1), -1)
        
        # Concat
        inputs = torch.cat([padded_feats, act_emb, team_emb, len_feat], dim=2)
        
        # Pack & GRU
        packed = pack_padded_sequence(inputs, lengths.cpu(), batch_first=True, enforce_sorted=False)
        _, h_n = self.gru(packed)
        
        last_hidden = h_n[-1] # (Batch, Hidden)
        
        # Classification
        logits = self.classifier(last_hidden)
        return logits

# ==========================================
# 4. Training Loop
# ==========================================
def build_team_mapping(df):
    unique_teams = df['team_id'].unique()
    for idx, team_id in enumerate(sorted(unique_teams)):
        TEAM_TO_IDX[team_id] = idx
    Config.NUM_TEAMS = len(TEAM_TO_IDX) + 1
    print(f"âœ… Team Mapping Built: {len(TEAM_TO_IDX)} teams")

def run_training():
    os.makedirs(Config.WEIGHT_DIR, exist_ok=True)
    
    # 1. Load & Label Data
    print("ğŸ“‚ Loading CSVs...")
    # train.csvê°€ ì—¬ëŸ¬ ê°œë¼ë©´ í•©ì³ì•¼ í•¨. ì—¬ê¸°ì„  í•˜ë‚˜ë¼ê³  ê°€ì •
    if os.path.isdir(Config.TRAIN_DIR):
        files = glob.glob(os.path.join(Config.TRAIN_DIR, '*.csv'))
        train_df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)
    else:
        train_df = pd.read_csv(os.path.join(Config.TRAIN_DIR, 'train.csv'))
        
    match_df = pd.read_csv(Config.MATCH_INFO_PATH)
    
    # Labeling
    labeled_df = label_game_state(train_df, match_df)
    
    # Team Mapping
    build_team_mapping(labeled_df)
    
    # 2. Dataset Split (Phase ë‹¨ìœ„)
    # Train/Val Split (ê²Œì„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ”ê²Œ ì¢‹ì§€ë§Œ í¸ì˜ìƒ Random Split)
    # DataFrameì˜ 'phase' ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ unique phase ì¶”ì¶œ í›„ split
    phases = labeled_df['phase'].unique()
    train_phases, val_phases = train_test_split(phases, test_size=0.2, random_state=42)
    
    train_data = labeled_df[labeled_df['phase'].isin(train_phases)]
    val_data = labeled_df[labeled_df['phase'].isin(val_phases)]
    
    train_ds = GameStateDataset(train_data)
    val_ds = GameStateDataset(val_data)
    
    train_loader = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True, collate_fn=collate_fn)
    val_loader = DataLoader(val_ds, batch_size=Config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn)
    
    # 3. Model Setup
    model = GameStateRNN().to(Config.DEVICE)
    criterion = nn.CrossEntropyLoss() # Multi-class Classification
    optimizer = optim.Adam(model.parameters(), lr=Config.LR)
    
    best_acc = 0.0
    
    print("ğŸš€ Training Game State Classifier (RNN)...")
    
    for epoch in range(Config.EPOCHS):
        model.train()
        correct = 0
        total = 0
        loss_sum = 0
        
        for batch in tqdm(train_loader, desc=f"Ep {epoch+1}"):
            batch = [b.to(Config.DEVICE) for b in batch]
            feats, lens, actions, teams, raw_lens, labels = batch
            
            optimizer.zero_grad()
            
            logits = model(feats, lens, actions, teams, raw_lens)
            loss = criterion(logits, labels)
            
            loss.backward()
            optimizer.step()
            
            loss_sum += loss.item()
            preds = torch.argmax(logits, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
            
        train_acc = correct / total
        avg_loss = loss_sum / len(train_loader)
        
        # Validation
        model.eval()
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            for batch in val_loader:
                batch = [b.to(Config.DEVICE) for b in batch]
                feats, lens, actions, teams, raw_lens, labels = batch
                
                logits = model(feats, lens, actions, teams, raw_lens)
                preds = torch.argmax(logits, dim=1)
                val_correct += (preds == labels).sum().item()
                val_total += labels.size(0)
                
        val_acc = val_correct / val_total
        
        print(f"   Loss: {avg_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}")
        
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), os.path.join(Config.WEIGHT_DIR, "state_classifier.pth"))
            print(f"   ğŸ’¾ Best Model Saved (Acc: {best_acc:.4f})")

if __name__ == '__main__':
    run_training()